With the wide application of knowledge graphs in the industry, numerous knowledge-graph-based applications have entered people's lives, such as e-commerce systems, medical health management systems, etc. In order to fully utilize the knowledge in the graph, knowledge representation learning embeds entities and relationships in the graph into a low-dimensional continuous space while preserving their semantic information, which helps various downstream tasks applications. Through knowledge representation learning, it is possible to predict user preferences for products or disease diagnosis. With the growth of knowledge graph data and the application on personal computers, mobile phones, and other mobile devices, the processing and storage of knowledge graphs are gradually distributed across multiple nodes. The target domain knowledge graph on the above nodes is usually a subset of the source domain knowledge graph and will continuously introduce other entities and relationships during user use. However, these introduced entities and relationships may contain new unseen entities and relationships that are not defined in the source domain knowledge graph entity set and relationship set. Classic knowledge representation methods cannot obtain vector representations of these unseen entities and relationships, making it difficult to complete the knowledge representation task well. In addition, considering the cost of merging and the need to protect user data privacy, the target domain and source domain knowledge graphs cannot be merged, resulting in the problem of cross-domain knowledge representation.

To solve this problem, this paper uses the algorithmic idea of meta-learning to simulate unseen entities and relationships on the target domain knowledge graph through labels in the training task, helping the model learn the ability to handle new entities and relationships in the target domain graph. At the same time, ontology information is introduced to provide semantic support for the representation learning of unseen entities and relationships. This mainly solves two problems in cross-domain knowledge representation learning: (1) current representation learning models for cross-domain knowledge graphs mostly use graphic structural information to learn the representation of unseen entities and relationships and have not been able to fully utilize other semantic information in the knowledge graph to supplement the representation learning. (2) Faced with cross-domain knowledge graphs, how to learn the representation ability of new entities and new relationships in training and generalize the model's learning ability to the representation learning task of the target domain knowledge graph.

This paper proposes a knowledge representation learning framework based on ontology information and meta-learning for cross-domain knowledge graphs. It mainly includes: for newly appeared relationships in cross-domain knowledge representation learning, using relationship graph convolutional networks to combine the topology information of relationships and ontology information based on relationship topology structure and description text to jointly learn and obtain the representation of unseen relationships; for newly appeared entities in cross-domain knowledge representation learning, using the adjacency relationship features of entities to aggregate the initial representation and then using a complex graph convolutional network to fully utilize the known entity and relationship information in the knowledge graph to learn and update the vector representation of the entire target domain entities and relationships. In the model training process, meta-learning is used to partition tasks and simulate new entities and new relationships in cross-domain scenarios through labels, thus completing the knowledge representation learning task learned from the source domain knowledge embedding to the target domain knowledge representation learning.

This paper verifies the effectiveness of cross-domain knowledge representation learning based on link prediction tasks and compares with multiple benchmark models. The experimental results prove the effectiveness of the proposed meta-learning ontology-enhanced cross-domain knowledge representation learning model.